{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLDTVWKq7-ei"
   },
   "source": [
    "# Tomo-SIREN \n",
    "\n",
    "Made for Jakob, to demystify neural fields.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vedranaa/fibre-pack/blob/main/fibre_packer_demo.ipynb)\n",
    "\n",
    "\n",
    "Author: vand@dtu.dk, 2025\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2717,
     "status": "ok",
     "timestamp": 1661768460156,
     "user": {
      "displayName": "Vedrana Andersen Dahl",
      "userId": "01302071591439961329"
     },
     "user_tz": -120
    },
    "id": "bZNXlxmEj0FC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# !pip install phantominator -q\n",
    "import phantominator\n",
    "import scipy.interpolate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I need an image and its projections. I will work with normalized coordinates, so the image is defined on [-1, 1]x[-1, 1]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1661768460157,
     "user": {
      "displayName": "Vedrana Andersen Dahl",
      "userId": "01302071591439961329"
     },
     "user_tz": -120
    },
    "id": "vltmwH8ySIWd"
   },
   "outputs": [],
   "source": [
    "def project_image(image, thetas, nr_B=128, nr_S=None):\n",
    "    '''Forward project the (square) image.\n",
    "    \n",
    "    image: 2D grayscale image to project\n",
    "    thetas: projection angles in radians\n",
    "    nr_B : int, number of detector bins\n",
    "    nr_S : int, number of samples along every projection ray, defaults to nr_B \n",
    "\n",
    "    Returns: nr_B projection values\n",
    "    ''' \n",
    "\n",
    "    nr_S = nr_S or nr_B\n",
    "    r, c = image.shape\n",
    "\n",
    "    # Define interpolation grid in normalized coordinates\n",
    "    b, s = np.linspace(-1, 1, nr_B), np.linspace(-1, 1, nr_S)\n",
    "    B, S = np.meshgrid(b, s, indexing='ij')  # this indexing is used by torch\n",
    "\n",
    "    # Rotate interpolation grid\n",
    "    cos_a, sin_a = np.cos(thetas), np.sin(thetas)\n",
    "    X = S[..., None] * cos_a - B[..., None] * sin_a\n",
    "    Y = S[..., None] * sin_a + B[..., None] * cos_a\n",
    "\n",
    "    # Interpolate using normalized coordinates\n",
    "    interp = scipy.interpolate.RegularGridInterpolator(\n",
    "        (np.linspace(-1, 1, r), np.linspace(-1, 1, c)), \n",
    "        image,\n",
    "        bounds_error=False,  # don't raise error for out-of-bounds\n",
    "        fill_value=0 # fill with 0 for out-of-bounds\n",
    "    )\n",
    "    val = interp((X, Y))\n",
    "    p = val.mean(axis=0).T  # Projections in rows of sinogram\n",
    "    return p\n",
    "    \n",
    "\n",
    "\n",
    "image = phantominator.shepp_logan(256)\n",
    "nr_B = 128\n",
    "nr_thetas = 90\n",
    "thetas = np.linspace(0., np.pi, nr_thetas, endpoint=False)\n",
    "sinogram = project_image(image, thetas, nr_B=100)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(image)\n",
    "ax[0].set_title('GT image')\n",
    "ax[1].imshow(sinogram)\n",
    "ax[1].set_title('GT sinogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I need a network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SineLayer(nn.Module):\n",
    "    # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of omega.\n",
    "    \n",
    "    # If is_first=True, omega is a frequency factor which simply multiplies the activations before the \n",
    "    # nonlinearity. Different signals may require different omega in the first layer - this is a \n",
    "    # hyperparameter.\n",
    "    \n",
    "    # If is_first=False, then the weights will be divided by omega so as to keep the magnitude of \n",
    "    # activations constant, but boost gradients to the weight matrix (see supplement Sec. 1.5)\n",
    "    \n",
    "    def __init__(self, indim, outdim, bias=True, is_first=False, omega=30):\n",
    "        super().__init__()\n",
    "        self.omega = omega\n",
    "        self.is_first = is_first\n",
    "        self.indim = indim\n",
    "        self.linear = nn.Linear(indim, outdim, bias=bias)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.linear.weight.uniform_(-1 / self.indim, 1 / self.indim)      \n",
    "            else:\n",
    "                self.linear.weight.uniform_(-np.sqrt(6 / self.indim) / self.omega, \n",
    "                                             np.sqrt(6 / self.indim) / self.omega)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return torch.sin(self.omega * self.linear(input))  # Here is sine activation!!!\n",
    "    \n",
    "    \n",
    "class Siren(nn.Module):\n",
    "    def __init__(self, indim=2, outdim=1, nr_hidden=3, hiddendim=256, \n",
    "                 outermost_linear=True, first_omega=30, hidden_omega=30):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "        layers.append(SineLayer(indim, hiddendim, is_first=True, omega=first_omega))\n",
    "\n",
    "        for i in range(nr_hidden):\n",
    "            layers.append(SineLayer(indim=hiddendim, outdim=hiddendim, \n",
    "                                      is_first=False, omega=hidden_omega))\n",
    "\n",
    "        if outermost_linear:\n",
    "            final_linear = nn.Linear(hiddendim, outdim)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                final_linear.weight.uniform_(-np.sqrt(6 / hiddendim) / hidden_omega, \n",
    "                                              np.sqrt(6 / hiddendim) / hidden_omega)\n",
    "                \n",
    "            layers.append(final_linear)\n",
    "        else:\n",
    "            layers.append(SineLayer(indim=hiddendim, outdim=outdim, \n",
    "                                      is_first=False, omega=hidden_omega))\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "        \n",
    "\n",
    "    def forward(self, coords):\n",
    "        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n",
    "        output = self.net(coords)\n",
    "        return output    \n",
    "\n",
    "model = Siren(indim=2, outdim=1, nr_hidden=3, hiddendim=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_coordinates(size):\n",
    "    '''Helping function giving the normalized coordinates of the pixels in the \n",
    "    image as a torch tensor.'''\n",
    "    r, c = size\n",
    "    x, y = torch.linspace(-1, 1, r), torch.linspace(-1, 1, c)\n",
    "    X, Y = torch.meshgrid(x, y, indexing='ij')  \n",
    "    coords = torch.stack([X.flatten(), Y.flatten()], dim=1)  \n",
    "    return coords\n",
    "\n",
    "def show_predictions(model):\n",
    "\n",
    "    sizes = [(256, 256), (128, 128), (64, 64)]\n",
    "    fig, ax = plt.subplots(1, len(sizes), figsize=(12, 4))\n",
    "\n",
    "    with torch.no_grad():  # I say to torch that I will not ask it to optimize anything based on the computation in this block\n",
    "        for size, a in zip(sizes, ax):\n",
    "            coords = image_coordinates(size)\n",
    "            pred = model(coords).reshape(size)\n",
    "            a.imshow(pred.detach().numpy())\n",
    "            a.set_title(f'Predicted image {size}')\n",
    "        plt.show()\n",
    "\n",
    "show_predictions(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS IS HOW FAR I MANAGED IN THIS ITERATION."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1661768461337,
     "user": {
      "displayName": "Vedrana Andersen Dahl",
      "userId": "01302071591439961329"
     },
     "user_tz": -120
    },
    "id": "lpNMTJXqOt86"
   },
   "outputs": [],
   "source": [
    "#  Tomography functions (instead of nerf rendering)\n",
    "\n",
    "def project_model(model, theta, nr_B, nr_S=64, L_embed=6):\n",
    "    '''Forward project the model.'''\n",
    "\n",
    "    b = tf.linspace(-1, 1, nr_B)\n",
    "    s = tf.linspace(-1, 1, nr_S)  # TODO: s (or S) may be randomized (slightly permuted)\n",
    "    B, S = tf.meshgrid(b, s, indexing='xy')  \n",
    "    pts = tf.stack([B, S], -1)\n",
    "    pts_flat = tf.reshape(pts, [-1, 2])\n",
    "\n",
    "    cos_a = np.cos(theta)\n",
    "    sin_a = np.sin(theta)\n",
    "    rot = np.array([[sin_a, cos_a], [cos_a, -sin_a]])\n",
    "    pts_flat = tf.reduce_sum(pts_flat[..., None, :] * rot, -1)  # practically  matmul\n",
    "   \n",
    "    pts_flat = posenc(pts_flat, L_embed=L_embed)\n",
    "    out = model(pts_flat)\n",
    "    out = tf.reshape(out, (nr_B, nr_S))   \n",
    "\n",
    "    w = 1/nr_S  # with randomized s weights will not be equal, but computed from s\n",
    "    p = w * tf.reduce_sum(out, axis = -1)\n",
    "\n",
    "    return p \n",
    "\n",
    "   \n",
    "def evaluate_model(model, N=128, L_embed=6):\n",
    "    '''Evaluate the model on the image grid.'''\n",
    "\n",
    "    l = tf.linspace(-1, 1, N)\n",
    "    i, j = tf.meshgrid(l, l, indexing='xy')\n",
    "    pts = tf.stack([i, j], -1)\n",
    "    pts_flat = tf.reshape(pts, [-1, 2])\n",
    "    pts_flat = posenc(pts_flat, L_embed=L_embed)\n",
    "    out = model(pts_flat)\n",
    "    out = tf.reshape(out, (N, N))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 64972,
     "status": "ok",
     "timestamp": 1661768526303,
     "user": {
      "displayName": "Vedrana Andersen Dahl",
      "userId": "01302071591439961329"
     },
     "user_tz": -120
    },
    "id": "GvR-v3uzCFYQ",
    "outputId": "cef8aae0-e71f-4e84-b988-a6f2696f890b"
   },
   "outputs": [],
   "source": [
    "# Fit model to projections\n",
    "model = init_model()\n",
    "optimizer = tf.keras.optimizers.Adam(5e-4)\n",
    "\n",
    "N_iters = 20\n",
    "nr_S = 128  # image side, as long as s is not randomized\n",
    "losses = []\n",
    "\n",
    "sinogram = tf.cast(sinogram, dtype=tf.float32)  # tf requires float32\n",
    "\n",
    "for i in range(N_iters+1):\n",
    "    for j in np.random.permutation(thetas.size):\n",
    "\n",
    "        theta = thetas[j]\n",
    "        target = sinogram[j]\n",
    "    \n",
    "        with tf.GradientTape() as tape:\n",
    "            p = project_model(model, theta, nr_B=nr_B, nr_S=nr_S) \n",
    "            loss = tf.reduce_mean(tf.square(p - target))\n",
    "        \n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        losses.append(loss.numpy())\n",
    "\n",
    "\n",
    "    reconstruction = evaluate_model(model, N=64)\n",
    "        \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    ax[0].imshow(reconstruction)\n",
    "    ax[0].set_title(f'Iteration: {i}')\n",
    "    ax[1].plot(losses)\n",
    "    ax[1].set_title('Loss')\n",
    "    plt.show()\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "executionInfo": {
     "elapsed": 2742,
     "status": "ok",
     "timestamp": 1661768529031,
     "user": {
      "displayName": "Vedrana Andersen Dahl",
      "userId": "01302071591439961329"
     },
     "user_tz": -120
    },
    "id": "xomfnEfguyKD",
    "outputId": "5f1cf2a3-b0fe-435f-851b-f37b441b1890"
   },
   "outputs": [],
   "source": [
    "# Visualize the final result\n",
    "reconstruction = evaluate_model(model, N=image.shape[0])\n",
    "predicted_sinogram = tf.stack([project_model(model, t, nr_B=nr_B, nr_S=nr_S) for t in thetas])\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, figsize=(15, 10))\n",
    "ax[0, 0].imshow(image)\n",
    "ax[0, 0].set_title(f'GT image, max:{image.max():.02}, sum:{image.sum():.02}')\n",
    "ax[0, 1].imshow(reconstruction)\n",
    "ax[0, 1].set_title(f'Reconstruction, max:{reconstruction.numpy().max():.02}, sum:{reconstruction.numpy().sum():.02}')\n",
    "ax[0, 2].imshow(image - reconstruction, vmin=-1, vmax=1, cmap=plt.cm.bwr)\n",
    "ax[0, 2].set_title(f'Residual image')\n",
    "ax[1, 0].imshow(sinogram)\n",
    "ax[1, 0].set_title(f'GT sinogram, max:{sinogram.numpy().max():.02}, sum:{sinogram.numpy().sum():.02}')\n",
    "ax[1, 1].imshow(predicted_sinogram)\n",
    "ax[1, 1].set_title(f'Predicted sinogram, max:{predicted_sinogram.numpy().max():.02}, sum:{predicted_sinogram.numpy().sum():.02}')\n",
    "ax[1, 2].imshow(sinogram - predicted_sinogram, vmin=-0.1, vmax=0.1, cmap=plt.cm.bwr)\n",
    "ax[1, 2].set_title(f'Residual sinogram')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1661768529032,
     "user": {
      "displayName": "Vedrana Andersen Dahl",
      "userId": "01302071591439961329"
     },
     "user_tz": -120
    },
    "id": "Cls7702yGunk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tomo_nerf.ipynb",
   "provenance": [
    {
     "file_id": "1P_XdypvFkRUuG-nOI23_adbmoWdTusEM",
     "timestamp": 1661522030549
    },
    {
     "file_id": "1l5jEyXafegjkce2MYJnc5oXH4xK4L-4J",
     "timestamp": 1651073342570
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "withPyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
